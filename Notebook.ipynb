{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the housing dataset as a Pandas Dataframe\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summmary of each column in the df\n",
    "print(df.info())\n",
    "\n",
    "print('''\n",
    "yr_renovated and waterfront are only columns containing null values\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find average house price and base RMSE using average price per sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average price of houses\n",
    "avg_price_house = df.price.mean()\n",
    "avg_price_house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average price per square feet\n",
    "avg_price_sqft = (df.price / df.sqft_living).mean()\n",
    "avg_price_sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA checking if square feet is a strong predictor of housing price\n",
    "price_pred_base = df.sqft_living * avg_price_sqft\n",
    "rmse_base = mean_squared_error(df.price, price_pred_base, squared=False)\n",
    "\n",
    "# Very high rmse, livable square footage isn't a strong predictor\n",
    "round(rmse_base, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Nan values of 'waterfront' and 'year_renovated' columns to 0\n",
    "df.loc[df.waterfront.isna()==True, 'waterfront'] = 0\n",
    "df.loc[df.yr_renovated.isna()==True, 'yr_renovated'] = 0\n",
    "\n",
    "#Set all sqft_basement values of '?' to 0, then convert to floats.\n",
    "df.loc[df.sqft_basement=='?', 'sqft_basement'] = 0\n",
    "df.sqft_basement = df.sqft_basement.astype(float)\n",
    "\n",
    "# Convert 'date' to a datetime object and use these to create a 'year' column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].apply(lambda date: date.year)\n",
    "\n",
    "# Create an 'age' column to specify how old a house was at sale\n",
    "df['age'] = df['year'] - df['yr_built']\n",
    "\n",
    "#Drop unnecessary 'id', 'yr_built', 'year', and 'date' columns\n",
    "cols_to_drop = ['id', 'yr_built', 'year', 'date']\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "#Drop rows that contain null values in the 'view' column\n",
    "df.dropna(subset = ['view'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning variable for columns we would like to check for outliers\n",
    "target_cols = ['bathrooms', 'bedrooms', 'sqft_living']\n",
    "\n",
    "# assigning variable to predefined outlier column names\n",
    "outlier_cols = ['outlier_' + col for col in target_cols]\n",
    "z_scores = [stats.zscore(df[col]) \n",
    "                for col in target_cols]\n",
    "\n",
    "# for each column, checking to see if the z-score is above or below 3 standard deviations\n",
    "for outlier_col, z_score in zip(outlier_cols, z_scores):\n",
    "    df[outlier_col] = ((z_score > 3) | (z_score <-3))\n",
    "\n",
    "# initializes an empty query string \n",
    "query_empty = '({} == False)&'*(len(target_cols))\n",
    "\n",
    "# fills in the outlier column names\n",
    "query = query_empty[:-1].format(*outlier_cols)\n",
    "\n",
    "# selecting rows that do not have any outliers\n",
    "df = df.query(query)\n",
    "\n",
    "# dropping the outlier columns that we just made\n",
    "df = df.drop(columns=outlier_cols)\n",
    "\n",
    "# Drop the outlier house that contains 33 bedrooms\n",
    "df = df[df['bedrooms'] != 33]\n",
    "\n",
    "# Drop houses that were bought before construction\n",
    "df = df[df['age'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to visualize the # of homes sold by # of bedrooms\n",
    "df.hist('bedrooms');\n",
    "print('There is a relatively normal distribution of bedroom sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a histogram to visualize the # of homes sold by price\n",
    "print(\"Price has a positive skew\")\n",
    "df.hist('price', bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of correlations for each feature set in the dataframe\n",
    "corr_matrix = df.corr()\n",
    "# Create a boolean mask for all values on or above the matrix diagonal \n",
    "corr_matrix_mask = np.triu(np.ones_like(df.corr(), dtype=bool));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a heat map of correlation coefficient\n",
    "fig, ax = plt.subplots(figsize  =(15,15))\n",
    "sns.heatmap(\n",
    "            corr_matrix, \n",
    "            ax=ax, \n",
    "            annot=True, \n",
    "            mask= corr_matrix_mask,\n",
    "            cbar_kws={\"label\": \"Correlation\", \"orientation\": \"horizontal\", \"pad\": .2, \"extend\": \"both\"}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price will be our target value to predict, so we'll zero in on its correlations.\n",
    "plt.figure(figsize=(4,10))\n",
    "heatmap = sns.heatmap(df.corr()[['price']].sort_values(by='price', ascending=False), vmin=-1, vmax=1, linewidths=1, linecolor='black', annot=True, fmt='.2g', cmap=\"gist_heat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating visualizations for each of our features as they relate to the price of houses sold in our dataset\n",
    "\n",
    "x = df.drop('price', axis=1)\n",
    "y= df.price\n",
    "fig, axes = plt.subplots(ncols=3, nrows=6, figsize=(12, 12))\n",
    "fig.set_tight_layout(True)\n",
    "for index, col in enumerate(x.columns): \n",
    "    ax = axes[index//3][index%3]\n",
    "    ax.scatter(x[col], y, alpha=0.2)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"House price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Sqft Per Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the binning intervals for price\n",
    "bins = pd.interval_range(0,df.price.max(), freq=150000)\n",
    "\n",
    "# Creates a column where price values are sorted into bins\n",
    "df['price_bins'] = pd.cut(df.price, bins)\n",
    "\n",
    "# Finds the mean square footage for each price bin for each price bin\n",
    "grouped_means = df.groupby(\"price_bins\")['sqft_living'].mean()\n",
    "grouped_means = grouped_means.reset_index().dropna(subset=['sqft_living'])\n",
    "\n",
    "# Breaks up the bins into a readable format for plotting\n",
    "x_labels = [str(interval.left/1000000) + ' - ' + str(interval.right/1000000)\n",
    "            for interval in grouped_means['price_bins']\n",
    "           ]\n",
    "# Overwrite raw bins with readable format for easy plotting\n",
    "grouped_means['price_bins'] = x_labels\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "plt.rc('font', size=12) \n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Plots price bins and average livable space\n",
    "ax = sns.barplot(y='sqft_living',x='price_bins', data=grouped_means)\n",
    "\n",
    "# Modify plot label attributes\n",
    "plt.xticks(rotation=90)\n",
    "ax.set(xlabel='Price Range ($ Millions)', ylabel='Avg. Livable Space (Sqft)')\n",
    "plt.title(\"Average Livable Space by Price Range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average price by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold by each value for grade\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['grade']\n",
    "y = df['price']\n",
    "ax = sns.barplot(x=x,y=y, data=df)\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set(xlabel='Grade', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price by Grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Price by bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold by number of bathrooms\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['bathrooms']\n",
    "y = df['price']\n",
    "ax = sns.barplot(x=x,y=y, data=df)\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set(xlabel='Bathroom', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price by Number of Bathrooms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Price by View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold by number of views\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['view']\n",
    "y = df['price']\n",
    "ax = sns.barplot(x=x,y=y, data=df)\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set(xlabel='View', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price by View\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Price by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold by condition\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['condition']\n",
    "y = df['price']\n",
    "ax = sns.barplot(x=x,y=y, data=df)\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set(xlabel='condition', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price by Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Price by Waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold based on whether or not they are on the water\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['waterfront']\n",
    "y = df['price']\n",
    "ax = sns.barplot(x=x,y=y, data=df)\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set_xticklabels(['Not On Waterfront', 'On Waterfront'])\n",
    "ax.set(xlabel='waterfront', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price by Waterfront\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot comparing sqft of neighbors to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a visualization to understand the mean price of homes sold based on the 15 closest neighbors\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Creates a bar plot of our target params\n",
    "x = df['sqft_living15']\n",
    "y = df['price']\n",
    "\n",
    "ax = sns.regplot(x=x,y=y, data=df, line_kws={'color': 'r'})\n",
    "\n",
    "# Modify plot label attributes\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "ax.set(xlabel='Sqft of 15 closest Neighbors ', ylabel='Avg. Price')\n",
    "plt.title(\"Home prices based on sqft of 15 closest Neighbors\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot comparing sqft of neighbors to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the binning intervals for price\n",
    "bins = pd.interval_range(0,df.price.max(), freq=150000)\n",
    "\n",
    "# Creates a column where price values are sorted into bins\n",
    "df['price_bins'] = pd.cut(df.price, bins)\n",
    "\n",
    "# Finds the mean square footage for the 15 closest neighbors for each price bin for each price bin\n",
    "grouped_means = df.groupby(\"price_bins\")['sqft_living15'].mean()\n",
    "grouped_means = grouped_means.reset_index().dropna(subset=['sqft_living15'])\n",
    "\n",
    "# Breaks up the bins into a readable format for plotting\n",
    "x_labels = [str(interval.left/1000000) + ' - ' + str(interval.right/1000000)\n",
    "            for interval in grouped_means['price_bins']\n",
    "           ]\n",
    "\n",
    "# Overwrite raw bins with readable format for easy plotting\n",
    "grouped_means['price_bins'] = x_labels\n",
    "\n",
    "# Initializes plot and style parameters\n",
    "plt.rc('font', size=12) \n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "# Plots price bins and average livable space\n",
    "ax = sns.barplot(y='sqft_living15',x='price_bins', data=grouped_means)\n",
    "\n",
    "# Modify plot label attributes\n",
    "plt.xticks(rotation=90)\n",
    "ax.set(xlabel='Price Range ($ Millions)', ylabel='Avg. Sqft of 15 closet neighbors')\n",
    "plt.title(\"Average Sqft of 15 closest neighbors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('price_bins', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the new 'age' column and our target column 'price' for the independent features\n",
    "X = df.drop(['price', 'age'], axis = 1)\n",
    "\n",
    "# Set our dependent variable as price\n",
    "y = df.price\n",
    "  \n",
    "# Split up our independent and dependent variables into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains our model on our baseline values\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(X_train, y_train)\n",
    "\n",
    "# predicting test prices based on the X_test\n",
    "y_predict_dummy_mean = lm_dummy_mean.predict(X_test)\n",
    "\n",
    "# Find the error of our dummy model\n",
    "rmse_lr0 = mean_squared_error(y_test, y_predict_dummy_mean, squared=False)\n",
    "print(r2_score(y_test, y_predict_dummy_mean), rmse_lr0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:  including 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the # of homes sold by their age\n",
    "df.hist('age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dependent variable from the independent columns\n",
    "X = df.drop(['price'], axis = 1)\n",
    "\n",
    "# Set our dependent variable as price\n",
    "y = df['price']\n",
    "\n",
    "# Split up our independent and dependent variables into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict price with the trained model\n",
    "pred_lr1 = lr.predict(X_test)\n",
    "\n",
    "# Get the coefficient of determination for training and test data\n",
    "train_score_lr1 = lr.score(X_train, y_train)\n",
    "test_score_lr1 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the error of our predicted y test values\n",
    "rmse_lr1 = mean_squared_error(y_test, pred_lr1, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score_lr1, test_score_lr1, rmse_lr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_1 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_1_mean = np.mean(scores_simple_1['train_score'])\n",
    "simple_1_mean_test = np.mean(scores_simple_1['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the QQ Plot to understand the distribution of residuals\n",
    "residuals1 = (y_test - pred_lr1)\n",
    "sm.graphics.qqplot(residuals1, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "\n",
    "residuals1 = (y_test - pred_lr1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr1, residuals1, alpha=.1)\n",
    "ax.plot(pred_lr1, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr1, data = df, line_kws={'color':'r'}, scatter_kws={'alpha':0.1});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: log transform 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dependent variable from the independent columns\n",
    "X = df.drop(['price'], axis = 1)\n",
    "\n",
    "# Set our dependent variable as the natural log of price\n",
    "y = np.log(df['price'])\n",
    "\n",
    "# Split up our independent and dependent variables into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict price with the trained model\n",
    "pred_lr2 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the score method to see how well our model performed based on how we trained it\n",
    "train_score_lr2 = lr.score(X_train, y_train)\n",
    "test_score_lr2 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr2 = mean_squared_error(np.exp(y_test), np.exp(pred_lr2), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr2, test_score_lr2, rmse_lr2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the QQ Plot to understand the distribution of residuals\n",
    "residuals2 = (y_test - pred_lr2)\n",
    "sm.graphics.qqplot(residuals2, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals2 = (y_test - pred_lr2)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr2, residuals2, alpha=.1)\n",
    "ax.plot(pred_lr2, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr2, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_2 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_2_mean = np.mean(scores_simple_2['train_score'])\n",
    "simple_2_mean_test = np.mean(scores_simple_2['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the VIF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a constant column\n",
    "df_temp = sm.add_constant(df)\n",
    "\n",
    "# Checking the Multicollinearity between the features\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_temp.values, i) for i in range(df_temp.values.shape[1])]\n",
    "vif[\"features\"] = df_temp.columns\n",
    "\n",
    "print(vif.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:  creating dummy columns for zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds dummy zipcode columns\n",
    "df = df.join(pd.get_dummies(df['zipcode'], prefix = 'x', drop_first = True))\n",
    "df.drop('zipcode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dependent variable from the independent columns\n",
    "X = df.drop(['price'], axis = 1)\n",
    "\n",
    "# Set our dependent variable as the natural log of price\n",
    "y = np.log(df['price'])\n",
    "\n",
    "# Split up our independent and dependent variables into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_lr3 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the score method to see how well our model performed based on how we trained it\n",
    "train_score_lr3 = lr.score(X_train, y_train)\n",
    "test_score_lr3 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr3 = mean_squared_error(np.exp(y_test), np.exp(pred_lr3), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr3, test_score_lr3, rmse_lr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making an OLS table to check for feature significance\n",
    "X = sm.add_constant(X)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_3 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_3_mean = np.mean(scores_simple_3['train_score'])\n",
    "simple_3_mean_test = np.mean(scores_simple_3['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the QQ Plot\n",
    "residuals3 = (y_test - pred_lr3)\n",
    "sm.graphics.qqplot(residuals3, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals3 = (y_test - pred_lr3)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr3, residuals3, alpha=.1)\n",
    "ax.plot(pred_lr3, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr3, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4:  dropping features with high p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use summary above to drop features with high p_values\n",
    "X = df.drop(['price', 'x_98002', 'x_98003', 'sqft_basement', 'bedrooms'], axis = 1)\n",
    "\n",
    "# Set our dependent variable as the natural log of price\n",
    "y = np.log(df['price'])\n",
    "\n",
    "# Split up our independent and dependent variables into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_lr4 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the score method to see how well our model performed based on how we trained it\n",
    "train_score_lr4 = lr.score(X_train, y_train)\n",
    "test_score_lr4 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr4 = mean_squared_error(np.exp(y_test), np.exp(pred_lr4), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr4, test_score_lr4, rmse_lr4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the OLS for values of feature significance\n",
    "X = sm.add_constant(X)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_4 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_4_mean = np.mean(scores_simple_4['train_score'])\n",
    "simple_4_mean_test = np.mean(scores_simple_4['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the normal distribution of our residuals\n",
    "residuals4 = (y_test - pred_lr4)\n",
    "sm.graphics.qqplot(residuals4, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals4 = (y_test - pred_lr4)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr4, residuals4, alpha=.1)\n",
    "ax.plot(pred_lr4, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr4, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: adding back the zipcodes we dropped in our previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dependent variable and non-relevant features for independent variable\n",
    "X = df.drop(['price', 'sqft_basement', 'bedrooms'], axis = 1)\n",
    "\n",
    "# Set independent variable to the natural log of price\n",
    "y = df['price'] \n",
    "y = np.log(y)\n",
    "\n",
    "# Split our training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_lr5 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the score method to see how well our model performed based on how we trained it\n",
    "train_score_lr5 = lr.score(X_train, y_train)\n",
    "test_score_lr5 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr5 = mean_squared_error(np.exp(y_test), np.exp(pred_lr5), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr5, test_score_lr5, rmse_lr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the OLS for values of feature significance\n",
    "X = sm.add_constant(X)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_5 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_5_mean = np.mean(scores_simple_5['train_score'])\n",
    "simple_5_mean_test = np.mean(scores_simple_5['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the normal distribution of our residuals\n",
    "residuals5 = (y_test - pred_lr5)\n",
    "sm.graphics.qqplot(residuals5, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals5 = (y_test - pred_lr4)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr5, residuals5, alpha=.1)\n",
    "ax.plot(pred_lr5, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr5, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Our best LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dependent variable and non-relevant features for independent variable\n",
    "X = df.drop(['price', 'sqft_basement', 'bedrooms', 'sqft_above'], axis = 1)\n",
    "y = df['price'] \n",
    "y = np.log(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict price with the trained model\n",
    "pred_lr6 = lr.predict(X_test)\n",
    "\n",
    "# Get the coefficient of determination for training and test data\n",
    "train_score_lr6 = lr.score(X_train, y_train)\n",
    "test_score_lr6 = lr.score(X_test, y_test)\n",
    "\n",
    "# Take a peak at model coef\n",
    "lr.coef_[0]\n",
    "\n",
    "# Baseline housing cost without features\n",
    "lr.intercept_\n",
    "\n",
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr6 = mean_squared_error(np.exp(y_test), np.exp(pred_lr6), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr6, test_score_lr6, rmse_lr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making an OLS table to check for feature significance\n",
    "X = sm.add_constant(X)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_simple_6 = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_6_mean = np.mean(scores_simple_6['train_score'])\n",
    "simple_6_mean_test = np.mean(scores_simple_6['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the QQ Plot\n",
    "residuals6 = (y_test - pred_lr6)\n",
    "sm.graphics.qqplot(residuals6, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals6 = (y_test - pred_lr6)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr6, residuals6, alpha=.1)\n",
    "ax.plot(pred_lr6, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr6, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7:  Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dependent variable and non-relevant features for independent variable\n",
    "X = df.drop(['price', 'sqft_basement', 'sqft_lot15', 'sqft_above', 'bathrooms', 'sqft_living', 'grade'], axis = 1)\n",
    "y = df['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our training dataset\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficient of determination for training and test data\n",
    "score_train_poly = lr.score(X_train_poly, y_train)\n",
    "score_test_poly = lr.score(X_test_poly,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_poly = lr.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_poly_7 = mean_squared_error(y_test, pred_poly, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train_poly, score_test_poly, rmse_poly_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_complex_1 = cross_validate(\n",
    "                    lr, X_train_poly, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_complex_1_train = np.mean(scores_complex_1['train_score'])\n",
    "scores_complex_1_test = np.mean(scores_complex_1['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One of the test scores is negative, will not use model\n",
    "scores_complex_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the normal distribution of our residuals\n",
    "residuals = (y_test - pred_poly)\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals = (y_test - pred_poly)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_poly, residuals, alpha=.1)\n",
    "ax.plot(pred_poly, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_poly, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8: Linear Regression with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Making 4 new colmns - here we are turning grade into a polynomial and multiplying it by existing features which improves the correlation to price compared to using the initial features.\n",
    "df['grade_sqft_living'] = (df.grade**2) * df.sqft_living\n",
    "df['grade_sqft_above'] = (df.grade**2) * df.sqft_above\n",
    "df['grade_sqft_living15'] = (df.grade**2) * df.sqft_living15\n",
    "df['grade_bathrooms'] = (df.grade**2) * df.bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping columns that are not going to be used \n",
    "X = df.drop(['price', 'sqft_basement', 'sqft_lot15', 'sqft_above', 'bathrooms', 'sqft_living', 'grade'], axis = 1)\n",
    "y = df['price'] \n",
    "y = np.log(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model to our training dataset\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_lr8 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficient of determination for training and test data\n",
    "train_score_lr8 = lr.score(X_train, y_train)\n",
    "test_score_lr8 = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at model coef\n",
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline housing cost without features\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing our price to get an RMSE\n",
    "rmse_lr8 = mean_squared_error(np.exp(y_test), np.exp(pred_lr8), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_lr8, test_score_lr8, rmse_lr8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making an OLS table to check for feature significance\n",
    "X = sm.add_constant(X)\n",
    "sm.OLS(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate our model and find the mean of the training scores\n",
    "simple_7_mean = cross_validate(\n",
    "                    lr, X_train, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_simple_7 = np.mean(simple_7_mean['train_score'])\n",
    "simple_7_mean_test = np.mean(simple_7_mean['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the normal distribution of our residuals\n",
    "residuals8 = (y_test - pred_lr8)\n",
    "sm.graphics.qqplot(residuals8, dist=stats.norm, line=\"45\", fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals8 = (y_test - pred_lr8)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_lr8, residuals8, alpha=.1)\n",
    "ax.plot(pred_lr8, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_lr8, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9: A Polynomial model with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade_sqft_living'] = (df.grade**2) * df.sqft_living\n",
    "df['grade_sqft_above'] = (df.grade**2) * df.sqft_above\n",
    "df['grade_sqft_living15'] = (df.grade**2) * df.sqft_living15\n",
    "df['grade_bathrooms'] = (df.grade**2) * df.bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dependent column and those that were used in feature engineering\n",
    "X = df.drop(['price', 'sqft_basement', 'sqft_lot15', 'sqft_above', 'bathrooms', 'sqft_living', 'grade'], axis = 1)\n",
    "y = df['price'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty polynomial object- 2 degrees\n",
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our training dataset\n",
    "X_train_poly = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our test dataset\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty regression model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use poly training X and Y data for linear regression model\n",
    "lr.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficient of determination for training and test data\n",
    "score_train_poly = lr.score(X_train_poly, y_train)\n",
    "score_test_poly = lr.score(X_test_poly,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price with the trained model\n",
    "pred_poly = lr.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the error of our predicted price versus actual\n",
    "rmse_poly_9 = mean_squared_error(y_test, pred_poly, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train_poly, score_test_poly, rmse_poly_9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our training dataset\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Initialize an empty regression model\n",
    "model_1 = LinearRegression()\n",
    "\n",
    "# Cross validate our model and find the mean of the training scores\n",
    "scores_complex_2 = cross_validate(\n",
    "                    model_1, X_poly, y_train, cv=5, \n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_complex_2_train = np.mean(scores_complex_2['train_score'])\n",
    "scores_complex_2_test = np.mean(scores_complex_2['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the normal distribution of our residuals\n",
    "residuals = (y_test - pred_poly)\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for homoscedasticity \n",
    "residuals = (y_test - pred_poly)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pred_poly, residuals, alpha=.1)\n",
    "ax.plot(pred_poly, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Actual - Predicted Value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how our regression line fits our data\n",
    "sns.regplot(x = y_test, y = pred_poly, data = df, line_kws={'color':'r'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the RMSE's for each of the models we created - the RMSE's represent the difference between our actual test scores vs. our predicted test scores\n",
    "\n",
    "models = ['Using Price/Sqft', 'Model_Base', 'Model_1', 'Model_2', 'Model_3', 'Model_4', 'Model_5', \n",
    "          'Model_6', 'Model_7', 'Model_8', 'Model_9']\n",
    "RMSE = [rmse_base, rmse_lr0, rmse_lr1, rmse_lr2, rmse_lr3, rmse_lr4, \n",
    "        rmse_lr5, rmse_lr6, rmse_poly_7, rmse_lr8, rmse_poly_9]\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "ax.plot(models, RMSE);\n",
    "ax.scatter(models, RMSE);\n",
    "ax.set_ylabel('Root Mean Squared Error, Dollars')\n",
    "ax.set_title('Average Dollar Error by Model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Error of base price / sqft and Model 9\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "x = ['Base Price/Sqft', 'Our Model']\n",
    "y = [rmse_base, rmse_poly_9]\n",
    "ax.bar(x, y)\n",
    "ax.set_ylabel('Average Error (Dollars)')\n",
    "ax.set_title('Error Using Price/Sft vs Our Model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making an array of all the train score means for our cross e-vals\n",
    "x_ = np.array([simple_1_mean,\n",
    "    simple_2_mean,\n",
    "    simple_3_mean,\n",
    "    simple_4_mean,\n",
    "    simple_5_mean,\n",
    "    simple_6_mean,\n",
    "    scores_complex_1_train,\n",
    "    scores_simple_7,\n",
    "    scores_complex_2_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counter\n",
    "p = 0\n",
    "\n",
    "# Using a for loop to print out every train score\n",
    "for i in x_:\n",
    "    p += 1\n",
    "    print(f'The Train Score is {round(i, 3)} in model {p}')\n",
    "print('\\n')\n",
    "# Getting the train score that was the highest\n",
    "print(f'The Max Train score is {x_.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an array of all the test scores for our cross e-vals\n",
    "y_ = np.array([simple_1_mean_test,\n",
    "    simple_2_mean_test,\n",
    "    simple_3_mean_test,\n",
    "    simple_4_mean_test,\n",
    "    simple_5_mean_test,\n",
    "    simple_6_mean_test,\n",
    "    scores_complex_1_test,\n",
    "    simple_7_mean_test,\n",
    "    scores_complex_2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter\n",
    "m = 0\n",
    "\n",
    "# Using a for loop to print out every test score\n",
    "for i in y_:\n",
    "    m += 1\n",
    "    # to check if the test score is positive\n",
    "    if i <= 0:\n",
    "        print(f'{round(i, 3)} is not accurate for model {m}\\n')\n",
    "    else:\n",
    "        print(f'The Test score is {round(i, 3)} in model {m}\\n')\n",
    "print('\\n')\n",
    "\n",
    "# Return the hightest test score\n",
    "print(f'The highest test score is {y_.max()}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an arrray of the RMSE\n",
    "z_ = np.array([rmse_lr0,\n",
    "               rmse_lr1,\n",
    "               rmse_lr2,\n",
    "               rmse_lr3,\n",
    "               rmse_lr4,\n",
    "               rmse_lr5,\n",
    "               rmse_lr6,\n",
    "               rmse_poly_7,\n",
    "               rmse_lr8,\n",
    "               rmse_poly_9]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# counter\n",
    "b = 0\n",
    "\n",
    "# Using a for loop to return the RMSE for all the models\n",
    "for i in z_:\n",
    "    m += 1\n",
    "    print(f'The RMSE score is {round(i, 3)} in model {m}\\n')\n",
    "print('\\n')\n",
    "# Getting the lowest RMSE\n",
    "print(f'The lowest RMSE score is {z_.min()}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
